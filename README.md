# ğŸšŒ Chaskiway: Recomendador de Viajes EconÃ³micos por el PerÃº

**Chaskiway** es una aplicaciÃ³n web colaborativa desarrollada para el curso de Lenguaje de ProgramaciÃ³n 2. Su objetivo es ayudar a los usuarios a planificar viajes interprovinciales desde Lima, recomendando las mejores opciones segÃºn presupuesto, clima y calidad del servicio, integrando datos de mÃºltiples fuentes reales.

---

## ğŸ¯ Objetivo del Proyecto

Desarrollar una soluciÃ³n completa de extracciÃ³n, integraciÃ³n y visualizaciÃ³n de datos de viajes, aplicando tÃ©cnicas de scraping, consumo de APIs, procesamiento y visualizaciÃ³n interactiva.

### Objetivos EspecÃ­ficos
- **Recolectar** informaciÃ³n de pasajes, clima e imÃ¡genes de al menos tres fuentes distintas.
- **Integrar** los datos en una base centralizada y limpia.
- **Desarrollar** un sistema de recomendaciÃ³n personalizado.
- **Presentar** los resultados en una interfaz web moderna y visual.

---

## ğŸ—ï¸ Arquitectura y Flujo de Datos

```mermaid
graph TD
    A[RedBus (API interna)] --> B[Datos crudos JSON]
    C[API Clima (Open-Meteo)] --> D[Datos crudos CSV]
    E[API ImÃ¡genes (SerpAPI)] --> F[Enlaces CSV]
    B & D & F --> G[main.py: IntegraciÃ³n y limpieza]
    G --> H[Base de datos SQLite]
    H --> I[Frontend Streamlit]
```

1. **ExtracciÃ³n:**  
   - [`backend/scraping/redbus`](backend/scraping/redbus/): Extrae datos de viajes desde la API interna de RedBus (identificada por inspecciÃ³n de red).
   - [`backend/scraping/clima`](backend/scraping/clima/): Descarga y procesa datos de clima desde la API pÃºblica de Open-Meteo.
   - [`backend/scraping/imagenes`](backend/scraping/imagenes/): Obtiene enlaces de imÃ¡genes de la API de SerpAPI.

2. **IntegraciÃ³n:**  
   - [`main.py`](main.py) orquesta la limpieza y combinaciÃ³n de los datos, generando la base de datos final en `data/processed/viajes_grupales.db`.

3. **PresentaciÃ³n:**  
   - [`frontend/app.py`](frontend/app.py) consume la base de datos y presenta recomendaciones y visualizaciones interactivas.

---

## ğŸ“š Estructura del Proyecto

```
Viajes-Economicos-Chaskiway/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ scraping/         # Scrapers de RedBus, clima e imÃ¡genes ([README](backend/scraping/README.md))
â”‚   â”‚   â”œâ”€â”€ redbus/      # Scraper RedBus ([README](backend/scraping/redbus/README.md))
â”‚   â”‚   â”œâ”€â”€ clima/       # Scraper Clima ([README](backend/scraping/clima/README.md))
â”‚   â”‚   â””â”€â”€ imagenes/    # Scraper ImÃ¡genes ([README](backend/scraping/imagenes/README.md))
â”‚   â””â”€â”€ database/        # Esquema y carga de la base de datos ([README](backend/database/README.md))
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/             # Datos crudos extraÃ­dos de las fuentes ([README](data/raw/README.md))
â”‚   â””â”€â”€ processed/       # Datos integrados y base de datos final ([README](data/README.md))
â”‚
â”œâ”€â”€ frontend/            # Interfaz web en Streamlit ([README](frontend/README.md))
â”‚
â”œâ”€â”€ utils/               # Utilidades de validaciÃ³n y logging ([README](utils/README.md))
â”‚
â”œâ”€â”€ main.py              # Pipeline de integraciÃ³n de datos
â”œâ”€â”€ requirements.txt     # Dependencias del proyecto
â”œâ”€â”€ README.md            # (Este archivo)
â””â”€â”€ docs/                # DocumentaciÃ³n y presentaciones ([README](docs/README.md))
```

---

## ğŸ§‘â€ğŸ’» Equipo de Desarrollo

| Integrante                        | Usuario de GitHub         | Rol en el Proyecto                        |
|----------------------------------- |--------------------------|-------------------------------------------|
| **Jhon Jhayro Villegas Verde**    | `JhoJha`                 | Backend, Scraper RedBus, Base de Datos    |
| **Jonnathan JesÃºs Pedraza Laboriano** | `[UsuarioGitHubDeJonnathan]` | Backend, Scraper ImÃ¡genes, Frontend  |
| **David Ojeda Valdiviezo**        | `20210842`               | Backend, Scraper Clima, Dashboard         |

---

## ğŸ”‘ Fuentes de InformaciÃ³n

1. **RedBus:**  
   - Se utilizÃ³ la **API interna** identificada mediante inspecciÃ³n de red, permitiendo obtener datos estructurados de viajes (precios, horarios, empresas, asientos, ratings) de forma eficiente y robusta.
2. **API de Clima (Open-Meteo):**  
   - Provee datos histÃ³ricos y de pronÃ³stico para cada destino, sin requerir autenticaciÃ³n.
3. **API de ImÃ¡genes (SerpAPI):**  
   - Suministra imÃ¡genes representativas de alta calidad para cada destino usando Google Images.

---

## ğŸš€ EjecuciÃ³n paso a paso

### 1. Instala dependencias y configura el entorno

```bash
git clone https://github.com/JhoJha/Viajes-Economicos-Chaskiway.git
cd Viajes-Economicos-Chaskiway
python -m venv venv
source venv/bin/activate  # o .\venv\Scripts\activate en Windows
pip install -r requirements.txt
```

### 2. Configura las API keys

- Crea un archivo `.env` siguiendo el ejemplo en [`docs/API_KEYS.md`](docs/API_KEYS.md).
- Solo es necesaria la key de SerpAPI para imÃ¡genes.

### 3. Ejecuta los scrapers

```bash
python backend/scraping/redbus/run_scraper.py
python backend/scraping/clima/scraper.py
python backend/scraping/clima/procesador.py
python backend/scraping/imagenes/scraper.py
```

### 4. Ejecuta el pipeline de integraciÃ³n

```bash
python main.py
```
- Si falta algÃºn archivo crÃ­tico, el pipeline te avisarÃ¡ y se detendrÃ¡.

### 5. Levanta el frontend

```bash
streamlit run frontend/app.py
```

---

## ğŸ› ï¸ Dificultades Encontradas y Soluciones

- **IntegraciÃ³n de datos heterogÃ©neos:**  
  Se normalizaron nombres y formatos para combinar fuentes distintas.
- **LÃ­mites de APIs y manejo de claves:**  
  Se gestionaron claves con variables de entorno y manejo de errores.
- **Scraping de RedBus:**  
  Se identificÃ³ y utilizÃ³ la API interna mediante inspecciÃ³n de red, evitando el scraping HTML tradicional.
- **ColaboraciÃ³n y control de versiones:**  
  Se definiÃ³ una estrategia de ramas y uso de Pull Requests para evitar conflictos.

---

## ğŸ“¸ Capturas de pantalla

_Agrega aquÃ­ imÃ¡genes del dashboard y del buscador para ilustrar la app._

---

## ğŸ“„ DocumentaciÃ³n adicional

- Cada carpeta principal y de scrapers incluye su propio `README.md` explicativo.
- Consulta [`docs/API_KEYS.md`](docs/API_KEYS.md) para la gestiÃ³n de claves.
- PresentaciÃ³n final disponible en [`docs/presentacion_final.pptx`](docs/presentacion_final.pptx).

---

## ğŸ“¬ Contacto

Para mÃ¡s informaciÃ³n, contactar a: `20231515@lamolina.edu.pe`