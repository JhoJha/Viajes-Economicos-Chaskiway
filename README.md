# ğŸšŒ Chaskiway: Recomendador de Viajes EconÃ³micos por el PerÃº

**Chaskiway** es una aplicaciÃ³n web desarrollada como proyecto para el curso de Lenguaje de ProgramaciÃ³n 2. Su objetivo es ayudar a los usuarios a planificar viajes interprovinciales desde Lima de manera inteligente, recomendando las mejores opciones en funciÃ³n de su presupuesto, preferencias de clima y calidad del servicio.

---

## ğŸ¯ Objetivo del Proyecto

Desarrollar una aplicaciÃ³n web interactiva que integre y analice datos de mÃºltiples fuentes para ofrecer recomendaciones de viaje personalizadas. El proyecto demuestra la aplicaciÃ³n de tÃ©cnicas de web scraping, procesamiento de datos, creaciÃ³n de bases de datos y visualizaciÃ³n de informaciÃ³n en una soluciÃ³n de software completa y funcional.

### Objetivos EspecÃ­ficos
- **Recolectar** informaciÃ³n de pasajes, clima e imÃ¡genes de tres fuentes distintas.
- **Integrar** los datos recolectados en una Ãºnica base de datos centralizada.
- **Desarrollar** un algoritmo de recomendaciÃ³n simple basado en un sistema de puntuaciÃ³n.
- **Crear** un dashboard visual e interactivo con Streamlit para presentar los resultados al usuario.

---

## ğŸ§± Arquitectura y Flujo de Datos

El proyecto sigue un pipeline de datos claro y modular para garantizar la calidad y consistencia de la informaciÃ³n.

```
[Fuente 1: RedBus] --(Scraper)--> [Datos Crudos: JSONs] --+
                                                          |
[Fuente 2: API Clima] --(Scraper)--> [Datos Crudos: CSV] ----> [main.py: CombinaciÃ³n] --> [Base de Datos SQLite] --> [Frontend: Streamlit]
                                                          |
[Fuente 3: API ImÃ¡genes] --(Scraper)--> [Datos Crudos: JSON] --+
```

1.  **ExtracciÃ³n (Scraping):** Tres scripts independientes se encargan de recolectar los datos de sus respectivas fuentes y guardarlos en la carpeta `data/raw/`.
2.  **CombinaciÃ³n y Carga (ETL):** El script `main.py` actÃºa como orquestador. Lee los tres conjuntos de datos crudos, los limpia y los combina usando la ciudad de destino como clave comÃºn. El resultado se carga en una base de datos SQLite en `data/processed/`.
3.  **PresentaciÃ³n (Frontend):** La aplicaciÃ³n `frontend/app.py` se conecta Ãºnicamente a la base de datos final para leer los datos ya procesados y presentarlos al usuario.

---

## ğŸ“š Fuentes de InformaciÃ³n

1.  **Portal RedBus:** Se utiliza para extraer informaciÃ³n detallada de viajes (precios, horarios, empresas, ratings, asientos disponibles) mediante tÃ©cnicas de web scraping.
2.  **API MeteorolÃ³gica (Visual Crossing):** Provee datos histÃ³ricos y de pronÃ³stico del clima para cada ciudad de destino, permitiendo filtrar por preferencias climÃ¡ticas.
3.  **API de ImÃ¡genes (Pixabay):** Suministra imÃ¡genes representativas de alta calidad para cada destino, enriqueciendo la experiencia visual de la aplicaciÃ³n.

---

## ğŸš€ TecnologÃ­as Utilizadas

- **Lenguaje:** Python 3.11
- **Web Scraping:** `requests`, `beautifulsoup4` (si aplica)
- **Procesamiento de Datos:** `pandas`
- **Base de Datos:** `sqlite3`
- **Frontend:** `streamlit`
- **Control de Versiones:** Git y GitHub

---

## ğŸ‘¨â€ğŸ’» Equipo de Desarrollo

| Integrante | Usuario de GitHub | Rol en el Proyecto |
| :--- | :--- | :--- |
| **Jhon Jhayro Villegas Verde** | `JhoJha` | Backend, Scraper de RedBus y Base de Datos |
| **Jonnathan JesÃºs Pedraza Laboriano** | `jonnathan2023` | Backend, Scraper de ImÃ¡genes y Frontend |
| **David Ojeda Valdiviezo** | `20210842` | Backend, Scraper de Clima y Dashboard |

---

## Git Workflow: Estrategia de Ramas

Para asegurar una colaboraciÃ³n ordenada y eficiente, el proyecto utiliza un flujo de trabajo basado en ramas de funcionalidad (`feature branches`):

-   ğŸŒ³ **`main`**: Rama principal. Contiene Ãºnicamente las versiones estables y funcionales del proyecto. Solo se fusiona desde `dev` cuando una versiÃ³n ha sido probada y aprobada por el equipo.
-   ğŸ› ï¸ **`dev`**: Rama de desarrollo e integraciÃ³n. Es la rama donde se unen todos los avances. Antes de fusionar a `main`, todo debe funcionar correctamente en `dev`.
-   ğŸšŒ **`scraper-redbus`**: Rama dedicada exclusivamente al desarrollo del scraper de RedBus y la lÃ³gica de su base de datos. (Responsable: Jhon Villegas).
-   ğŸŒ¦ï¸ **`scraper-clima`**: Rama para el desarrollo del conector a la API de clima. (Responsable: David Ojeda Valdiviezo).
-   ğŸ–¼ï¸ **`scraper-imagenes`**: Rama para el desarrollo del conector a la API de imÃ¡genes. (Responsable: Jonnathan Pedraza).
-   ğŸ–¥ï¸ **`dashboard`**: Rama dedicada al desarrollo de la interfaz de usuario y las visualizaciones en Streamlit.

El flujo de trabajo es: cada integrante trabaja en su rama asignada, y una vez que su funcionalidad estÃ¡ completa, crea un **Pull Request** hacia la rama `dev` para su revisiÃ³n e integraciÃ³n.

---

## ğŸ“Œ Estado Actual del Proyecto

ğŸš§ **En Desarrollo.**

- [X] CreaciÃ³n de la estructura base del proyecto y repositorio.
- [X] DefiniciÃ³n de la estrategia de ramas y flujo de trabajo en Git.
- [ ] Desarrollo de los scrapers individuales.
- [ ] DiseÃ±o del esquema de la base de datos.
- [ ] ImplementaciÃ³n del pipeline de integraciÃ³n de datos.
- [ ] Desarrollo de la interfaz de usuario en Streamlit.

---

## ğŸ“ Contacto

Para mÃ¡s informaciÃ³n, contactar a: `20231515@lamolina.edu.pe`
